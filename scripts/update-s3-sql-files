#! /usr/bin/env bash

#
# A script to rename secure migrations from all environments to include .up.sql suffix
#
# This script should never need to be run more than once in each environment and can probably be removed.
#

set -u -o pipefail

readonly aws_command="aws"
readonly aws_bucket_prefix="transcom-ppp-app-"
readonly aws_bucket_suffix="-us-west-2"
readonly aws_path_prefix="secure-migrations"

readonly usage="usage: $0 <environment_name>"

#
# Pre-flight checks
#

if [[ -z "${1:-}" ]]; then
  echo "$usage"
  exit 1
fi
readonly environment="${1}"

# Ensure our `aws` command is the one infra has wrapped with aws-vault
command -v "$aws_command" 2> /dev/null | grep "ppp-infra/scripts/aws" &> /dev/null || \
  ( echo "error: aws command not pointing to 'ppp-infra/scripts/aws"
    echo "see https://github.com/transcom/ppp-infra/blob/master/transcom-ppp/README.md#using-aws-vault"
    exit 1
  )

bucket="${aws_bucket_prefix}${environment}${aws_bucket_suffix}"

# Find only the files that need to be renamed
filenames=$(${aws_command} s3api list-objects --bucket "${bucket}"  --prefix "${aws_path_prefix}/" | jq -r ".Contents[].Key" | grep -E -v ".up.sql" | grep "sql" | sort)

timestamp=$(date +"%Y/%m/%d %H:%M:%S UTC")

cat <<EOF > tagfile
  { "TagSet": [
      {
        "Key": "av-status",
        "Value": "CLEAN"
      },
      {
        "Key": "av-timestamp",
        "Value": "${timestamp}"
      },
      {
        "Key": "av-notes",
        "Value": "MANUAL"
      }
    ]
  }
EOF

# Copy to new name
for file in $filenames; do
  new_file="${file%.*}.up.sql"
  if [[ ! $(aws s3 ls  "s3://${bucket}/${new_file}") ]]; then
    if [[ ! $(${aws_command} s3 cp --sse AES256 "s3://${bucket}/${file}" "s3://${bucket}/${new_file}") ]]; then
		  # Download and upload the file and re-tag it to get around size limits
      secure_dir="./tmp/secure_migrations/${environment}/"
      mkdir -p "${secure_dir}"
      ${aws_command} s3 cp "s3://${bucket}/${file}" "${secure_dir}/${file}"
      ${aws_command} s3 cp --sse AES256 "${secure_dir}/${file}" "s3://${bucket}/${new_file}"
		  ${aws_command} s3api put-object-tagging --bucket "${bucket}" --key "${new_file}" --tagging "$(<tagfile)"
		fi
  fi
done

# Check for any missing files
${aws_command} s3api list-objects --bucket "${bucket}"  --prefix "${aws_path_prefix}/" | jq -r ".Contents[].Key" | grep -E -v ".up.sql" | grep "sql" | sort
