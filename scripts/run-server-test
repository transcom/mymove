#! /usr/bin/env bash

#
# Run golang server tests
#
# Set these environment variables to change behavior:
# - APPLICATION: 'app' or 'orders' will change which tests are run and which migrations are run for them
# - CIRCLECI: Will reduce parallelism and make the test output verbose
# - COVERAGE: '1' will enable test coverage flags
# - DRY_RUN: '1' will build the tests but not run them
# - JUNIT: '1' will run go-junit-report on test output
# - LONG_TEST: '1' will remove the '-short' flag and run extended tests
# - NO_DB: Will disable the db reset and migration steps
#
# Don't run tests in /cmd (those are done in acceptance testing) or for generated code (in /pkg/gen/ or mocks)
# Disable test caching with `-count 1` - caching was masking local test failures

set -eu -o pipefail

if [ "${APPLICATION}" == "app" ]; then
  package_list=$(go list ./... | grep -v ordersapi | grep -v \\/pkg\\/gen\\/ | grep -v \\/cmd\\/ | grep -v mocks)
elif [ "${APPLICATION}" == "orders" ]; then
  package_list=$(go list ./pkg/handlers/ordersapi)
else
  echo "Must provider the environment variable APPLICATION and set to 'app' or 'orders'"
  exit 1
fi

verbose_flag=""
parallel=8
failfast_flag="-failfast"
if [ -n "${CIRCLECI+x}" ]; then
	# Limit the maximum number of tests to run in parallel for CircleCI due to memory constraints.
  parallel=4
	# Add verbose (-v) so go-junit-report can parse it for CircleCI results
  verbose_flag="-v"
  # Don't fail fast in Circle CI so we can see all the tests that failed
  failfast_flag=""
fi

# Try to compile tests, but don't run them.
if [[ "${DRY_RUN:-}" == "1" ]]; then
  echo "Compiling tests only, not running"
  # shellcheck disable=SC2086
	go test -run=nope -parallel ${parallel} -count 1 ${package_list}
  exit 0
fi

# Like server_test but runs extended tests that may hit external services.
short_flag="-short"
if [[ "${LONG_TEST:-}" == "1" ]]; then
  short_flag=""
fi

# Add coverage tracker via go cover
coverage_flag=""
if [[ "${COVERAGE:-}" == "1" ]]; then
  coverage_flag="-coverprofile=coverage.out -covermode=count"
fi

# Set up the test DB instance and wipe it
# do not run db commands if NO_DB is set to 1
if [[ "${NO_DB:-}" -ne 1 ]]; then
  make db_test_reset db_test_migrate
fi

# Setup test output for reporting
test_dir="tmp/test-results/gotest/${APPLICATION}"
test_output_file="${test_dir}/go-test.out"
test_report_file="${test_dir}/go-test-report.xml"
mkdir -p "${test_dir}"

function junit_cleanup()
{
  # generate the junit report
  bin/go-junit-report < "${test_output_file}" > "${test_report_file}"
}

# Set up junit report and ensure its run on exit
if [[ "${JUNIT:-}" == "1" ]]; then
  if [ ! -f bin/go-junit-report ]; then
    make bin/go-junit-report
  fi
  # setup a trap incase the tests fail, we still want to generate the report
  trap junit_cleanup EXIT
fi

# shellcheck disable=SC2086
DB_NAME="${DB_NAME_TEST}" DB_PORT="${DB_PORT_TEST}" go test ${failfast_flag} -vet=off -parallel "${parallel}" -count 1 ${verbose_flag} ${coverage_flag} ${short_flag} ${package_list} | tee "${test_output_file}"
